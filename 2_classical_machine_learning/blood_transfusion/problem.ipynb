{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Machine Learning\n",
    "\n",
    "In case you do not dispose from a local environment please launch this repository from \n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/Talan-TechForData/datascience-solutions/HEAD?labpath=problem.ipynb) \n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Talan-TechForData/datascience-solutions/blob/main/1_exploratory_data_analysis/taxinyc_analysis/problem.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Situational description \n",
    "\n",
    "In this case we consider a classical dataset describing blood transfusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas matplotlib scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's the Blood Transfusion Service Center dataset, commonly used in ML. It typically contains features like recency, frequency, monetary, and time of donation.\n",
    "\n",
    "Attributes:\n",
    "\n",
    "- Recency (R): Number of months since the donor‚Äôs most recent blood donation.\n",
    "- Frequency (F): Total number of times the donor has donated blood.\n",
    "- Monetary (M): Total volume of blood donated in cubic centimeters (c.c.).\n",
    "- Time (T): Number of months since the donor‚Äôs first blood donation.\n",
    "- Class Donation in March 2007: Binary indicator (1 if the donor gave blood in March 2007, 0 otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/INRIA/scikit-learn-mooc/refs/heads/main/datasets/blood_transfusion.csv')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In this case what kind of problems can be solved with this dataset via ML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Consider the following piece of code. Explain what the piece of code does and the conclusions this might bring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df, hue='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exploratory analysis with the pairplot indicates that:\n",
    "\n",
    "- Recency, Frequency, and Monetary are the most informative features for predicting donor behavior.\n",
    "- Donors who have donated recently and more frequently (and thus have a higher cumulative donation amount) are more likely to donate again.\n",
    "- There is a potential issue with class imbalance and some redundancy between Frequency and Monetary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What does the following code does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "data = df.drop(columns=\"Class\")\n",
    "target = df[\"Class\"]\n",
    "\n",
    "model = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(random_state=0)\n",
    "cv_results = cross_validate(model, data, target, cv=cv, n_jobs=2)\n",
    "cv_results = pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds to the outcome of a cross validation exercise where the main task is to perform classification to determine the potential predictability of a donor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What does the following code do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gammas = np.logspace(-3, 2, num=30)\n",
    "param_name = \"svc__gamma\"\n",
    "train_scores, test_scores = validation_curve(\n",
    "    model,\n",
    "    data,\n",
    "    target,\n",
    "    param_name=param_name,\n",
    "    param_range=gammas,\n",
    "    cv=cv,\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "plt.errorbar(\n",
    "    gammas,\n",
    "    train_scores.mean(axis=1),\n",
    "    yerr=train_scores.std(axis=1),\n",
    "    alpha=0.95,\n",
    "    label=\"Training score\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    gammas,\n",
    "    test_scores.mean(axis=1),\n",
    "    yerr=test_scores.std(axis=1),\n",
    "    alpha=0.5,\n",
    "    label=\"Testing score\",\n",
    ")\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(r\"Value of hyperparameter $\\gamma$\")\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "_ = plt.title(\"Validation score of support vector machine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R. The following code performs:\n",
    "\n",
    "1. **Hyperparameter Tuning with `validation_curve`** ‚Äì The code evaluates different values of **gamma (ùõæ)** for an **SVM model** to analyze its effect on accuracy.  \n",
    "\n",
    "2. **Logarithmic Gamma Range** ‚Äì It generates **30 values** for gamma between \\(10^{-3}\\) and \\(10^2\\) using `np.logspace(-3, 2, num=30)`.  \n",
    "\n",
    "3. **Cross-Validation Performance** ‚Äì `validation_curve` computes training and testing scores across different gamma values using **cross-validation (cv)**.  \n",
    "\n",
    "4. **Bias-Variance Tradeoff** ‚Äì The **training curve** (high at large gamma values) and **testing curve** (peaking at an optimal gamma) help identify underfitting (low gamma) and overfitting (high gamma).  \n",
    "\n",
    "5. **Visualization with Error Bars** ‚Äì `plt.errorbar()` plots **mean accuracy** with **standard deviation** to show score variability for both training and testing sets.  \n",
    "\n",
    "6. **Logarithmic Scale for Better Interpretation** ‚Äì The x-axis uses `plt.xscale(\"log\")` to clearly display **exponential changes in gamma values** and their impact on model accuracy. üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Can you explain the following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LearningCurveDisplay\n",
    "\n",
    "train_sizes = np.linspace(0.1, 1, num=10)\n",
    "LearningCurveDisplay.from_estimator(\n",
    "    model,\n",
    "    data,\n",
    "    target,\n",
    "    train_sizes=train_sizes,\n",
    "    cv=cv,\n",
    "    score_type=\"both\",\n",
    "    scoring=\"accuracy\",  # this is already the default for classifiers\n",
    "    score_name=\"Accuracy\",\n",
    "    std_display_style=\"errorbar\",\n",
    "    errorbar_kw={\"alpha\": 0.7},  # transparency for better visualization\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\n",
    "_ = plt.title(\"Learning curve for support vector machine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Learning Curve Analysis** ‚Äì The code uses `LearningCurveDisplay.from_estimator` to visualize **how model performance changes** as the training set size increases, helping diagnose **bias vs. variance** issues.  \n",
    "\n",
    "2. **Training Set Variation** ‚Äì `train_sizes = np.linspace(0.1, 1, num=10)` tests model performance with training sizes from **10% to 100%**, showing how accuracy evolves with more data.  \n",
    "\n",
    "3. **Visualization with Error Bars** ‚Äì The plot includes **both training and validation scores** (`score_type=\"both\"`) with **error bars** (`std_display_style=\"errorbar\"`) to highlight variability, helping assess model **generalization**. üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
